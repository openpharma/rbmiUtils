---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# rbmiUtils <a href="https://openpharma.github.io/rbmiUtils/"> <img src="man/figures/rbmiUtils.png" align="right" width="140px" alt="rbmiUtils website" /> </a>



<!-- badges: start -->

[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
![CRAN status](https://www.r-pkg.org/badges/version/rbmiUtils)
[![R-CMD-check](https://github.com/openpharma/rbmiUtils/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/openpharma/rbmiUtils/actions/workflows/R-CMD-check.yaml)
[![test-coverage](https://github.com/openpharma/rbmiUtils/actions/workflows/test-coverage.yaml/badge.svg)](https://github.com/openpharma/rbmiUtils/actions/workflows/test-coverage.yaml)
<!-- badges: end -->

`rbmiUtils` extends the functionality of [`rbmi`](https://github.com/openpharma/rbmi) to support more streamlined workflows for multiple imputation in clinical trials. It is designed to simplify key tasks such as analysis execution, pooling, result tidying, and imputed data handling.


## Table of Contents

* [Installation](#installation)
* [Example](#example)
* [Dataset](#dataset)
* [Utilities](#utilities)
  * [Analysis Functions](#analysis-functions)
  * [Data Preparation](#data-preparation)
  * [Efficient Storage](#efficient-storage)
  * [Reporting](#reporting)
* [Development Status](#development-status)

## Installation

You can install the package from cran or the development version of `rbmiUtils` from GitHub:


Type | Source | Command
---|---|---
Release | CRAN | `install.packages("rbmiUtils")`
Development | GitHub | `remotes::install_github("openpharma/rbmiUtils")`


## Example

This example shows how to run a covariate-adjusted ANCOVA on imputed datasets using Bayesian multiple imputation:

```{r example, message = FALSE, warning = FALSE}
library(dplyr)
library(rbmi)
library(rbmiUtils)

data("ADMI")

# Setup
N_IMPUTATIONS <- 100
WARMUP <- 200
THIN <- 5

# Preprocessing
ADMI <- ADMI %>%
  mutate(
    TRT = factor(TRT, levels = c("Placebo", "Drug A")),
    USUBJID = factor(USUBJID),
    AVISIT = factor(AVISIT)
  )

# Define analysis variables
vars <- set_vars(
  subjid = "USUBJID",
  visit = "AVISIT",
  group = "TRT",
  outcome = "CHG",
  covariates = c("BASE", "STRATA", "REGION")
)

# Specify imputation method
method <- rbmi::method_bayes(
  n_samples = N_IMPUTATIONS,
  control = rbmi::control_bayes(
    warmup = WARMUP,
    thin = THIN
  )
)

# Run analysis
ana_obj <- analyse_mi_data(
  data = ADMI,
  vars = vars,
  method = method,
  fun = ancova
)

# Pool results and tidy
pool_obj <- pool(ana_obj)
tidy_df <- tidy_pool_obj(pool_obj)

# View results
print(tidy_df)
```

## Data Validation Example

Before running imputation, use `validate_data()` to catch common issues early:

```{r validation, eval = FALSE}
# Validate data before imputation
validate_data(ADMI, vars)

# Summarise missing data patterns
miss_summary <- summarise_missingness(ADMI, vars)
print(miss_summary$summary)
#> # A tibble: 2 x 5
#>   group   n_subjects n_complete n_monotone n_intermittent
#>   <fct>        <int>      <int>      <int>          <int>
#> 1 Placebo        250        206         38              6
#> 2 Drug A         250        214         32              4
```

## Datasets

The package includes two example datasets for demonstrating imputation and analysis:

* `ADEFF`: An example efficacy dataset for with missing data.
* `ADMI`: A large multiple imputation dataset with 100,000 rows and multiple visits, treatment arms, and stratification variables.

Use `?ADEFF` and `?ADMI` to view full dataset documentation.

## Utilities

### Analysis Functions

Core functions for running analyses on imputed data:

* `analyse_mi_data()`: Applies an analysis function (e.g., ANCOVA) to all imputed datasets.
* `tidy_pool_obj()`: Tidies and annotates pooled results for reporting.
* `get_imputed_data()`: Extracts long-format imputed datasets with original subject IDs mapped.
* `gcomp_responder()`: G-computation for binary responder endpoints using `{beeca}`.

### Data Preparation

Functions to validate and prepare data before imputation:

* `validate_data()`: Pre-flight validation of data structure, types, and completeness before calling `rbmi::draws()`.
* `prepare_data_ice()`: Builds `data_ice` from a flag column indicating intercurrent events.
* `summarise_missingness()`: Tabulates missing data patterns (complete, monotone, intermittent) by visit and treatment group.

### Efficient Storage

Functions to reduce storage requirements when working with many imputations:

* `reduce_imputed_data()`: Extracts only imputed values (originally missing), reducing storage by 90%+ for typical datasets.
* `expand_imputed_data()`: Reconstructs the full imputed dataset from reduced form for analysis.

### Reporting

Functions to format results for publication:

* `format_pvalue()`: Format p-values with configurable thresholds (e.g., "< 0.001").
* `format_estimate()`: Format estimates with confidence intervals (e.g., "1.23 (0.45, 2.01)").
* `format_results_table()`: Add formatted columns to tidy results for publication-ready tables.

```{r reporting-example, eval = FALSE}
# Format results for publication
tidy_df |>
  format_results_table() |>
  dplyr::select(description, est_ci, pval_fmt)
#> # A tibble
#>   description                         est_ci                pval_fmt
#>   <chr>                               <chr>                 <chr>
#> 1 Treatment Comparison at Week 24     -2.45 (-4.20, -0.70)
  0.006
#> 2 Least Squares Mean for Reference    5.20 (3.93, 6.47)     NA
```

These utilities wrap standard `rbmi` workflows for improved reproducibility and interpretability.

## Development Status

This package is experimental and under active development. Feedback and contributions are welcome via [GitHub issues](https://github.com/openpharma/rbmiUtils/issues) or pull requests.
